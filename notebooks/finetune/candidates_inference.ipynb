{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user010/Desktop/Programming/ML/En2RuTranslator\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "print(root_dir)\n",
    "assert os.path.exists(root_dir), f'Could not find root directory at {root_dir}'\n",
    "sys.path.insert(0, root_dir)\n",
    "\n",
    "from custom_utils.config_handler import read_config, pprint_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"root\": \"/Users/user010/Desktop/Programming/ML/En2RuTranslator\",\n",
      "  \"opus_model\": {\n",
      "    \"name\": \"opus-en-ru\",\n",
      "    \"model_and_tokenizer_name\": \"Helsinki-NLP/opus-mt-en-ru\"\n",
      "  },\n",
      "  \"nnlb_model\": {\n",
      "    \"name\": \"nnlb-1.3B-distilled\",\n",
      "    \"model_and_tokenizer_name\": \"facebook/nllb-200-distilled-1.3B\"\n",
      "  },\n",
      "  \"inference_dataset\": {\n",
      "    \"path\": \"/Users/user010/Desktop/Programming/ML/En2RuTranslator/data/processed/model_eval.csv\"\n",
      "  },\n",
      "  \"result_dataset\": {\n",
      "    \"path\": \"/Users/user010/Desktop/Programming/ML/En2RuTranslator/data/processed/model_eval_results.csv\",\n",
      "    \"cols\": {\n",
      "      \"reference\": \"target\",\n",
      "      \"candidates\": [\n",
      "        \"transformer-en-ru\",\n",
      "        \"nnlb-1.3B-distilled\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "overrides = [\"setup=inference\"]\n",
    "cfg = read_config(overrides=overrides)\n",
    "pprint_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "sample_texts = [\"Hey, how are you?\", \"My name is John Smith, I live in the United States of America.\",\n",
    "                \"I love NLP and Transformers!\"]\n",
    "\n",
    "def get_translations(model: AutoModelForSeq2SeqLM, tokenizer: AutoTokenizer, sample_texts: list,\n",
    "                     special_gen_params: dict = None) -> list:\n",
    "    special_gen_params = special_gen_params or {}\n",
    "    print(\"Tokenizing...\")\n",
    "    inputs = tokenizer(sample_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=600)\n",
    "    print(\"Generating...\")\n",
    "    translated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            **special_gen_params,\n",
    "            max_length=600,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    print(\"Decoding...\")\n",
    "    translated_texts = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
    "    return translated_texts\n",
    "\n",
    "def print_translations(source: list[str], target: list[str]):\n",
    "    assert len(source) == len(target), \"Source and target lists must be of same length\"\n",
    "    for src, tgt in zip(source, target):\n",
    "        print(f\"Source: {src}\")\n",
    "        print(f\"Target: {tgt}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_tokenizer_name = cfg.nnlb_model.model_and_tokenizer_name\n",
    "nnlb_tokenizer = AutoTokenizer.from_pretrained(model_and_tokenizer_name)\n",
    "nnlb_model = AutoModelForSeq2SeqLM.from_pretrained(model_and_tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user010/Desktop/Programming/ML/En2RuTranslator/venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Source: Hey, how are you?\n",
      "Target: Привет, как дела?\n",
      "\n",
      "Source: My name is John Smith, I live in the United States of America.\n",
      "Target: Меня зовут Джон Смит, я живу в Соединенных Штатах Америки.\n",
      "\n",
      "Source: I love NLP and Transformers!\n",
      "Target: Я люблю НЛП и Трансформеров!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translations = get_translations(nnlb_model, nnlb_tokenizer, sample_texts, \n",
    "                                special_gen_params={\"forced_bos_token_id\": nnlb_tokenizer.lang_code_to_id[\"rus_Cyrl\"]})\n",
    "print_translations(sample_texts, translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user010/Desktop/Programming/ML/En2RuTranslator/venv/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_and_tokenizer_name = cfg.opus_model.model_and_tokenizer_name\n",
    "opus_tokenizer = AutoTokenizer.from_pretrained(model_and_tokenizer_name)\n",
    "opus_model = AutoModelForSeq2SeqLM.from_pretrained(model_and_tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Generating...\n",
      "Decoding...\n",
      "Source: Hey, how are you?\n",
      "Target: Привет, как дела?\n",
      "\n",
      "Source: My name is John Smith, I live in the United States of America.\n",
      "Target: Меня зовут Джон Смит, я живу в Соединенных Штатах Америки.\n",
      "\n",
      "Source: I love NLP and Transformers!\n",
      "Target: Я люблю NLP и Transformers!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translations = get_translations(opus_model, opus_tokenizer, sample_texts)\n",
    "print_translations(sample_texts, translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The intention would also be to infiltrate terr...</td>\n",
       "      <td>Террористов также обучают методам проникновени...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Officials say that as the latest information a...</td>\n",
       "      <td>По последним данным представителей власти , в ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While the Balakot camp was reactivated by the ...</td>\n",
       "      <td>Джаиш-е-Мухаммад возобновили работу террористи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The incident in which Pakistan used drones to ...</td>\n",
       "      <td>В качестве яркого примера новой стратегии паки...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Officials tell OneIndia that terror groups wou...</td>\n",
       "      <td>Представители власти рассказали порталу OneInd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  The intention would also be to infiltrate terr...   \n",
       "1  Officials say that as the latest information a...   \n",
       "2  While the Balakot camp was reactivated by the ...   \n",
       "3  The incident in which Pakistan used drones to ...   \n",
       "4  Officials tell OneIndia that terror groups wou...   \n",
       "\n",
       "                                              target  \n",
       "0  Террористов также обучают методам проникновени...  \n",
       "1  По последним данным представителей власти , в ...  \n",
       "2  Джаиш-е-Мухаммад возобновили работу террористи...  \n",
       "3  В качестве яркого примера новой стратегии паки...  \n",
       "4  Представители власти рассказали порталу OneInd...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inference_ds = pd.read_csv(cfg.inference_dataset.path)\n",
    "inference_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 32\n",
    "num_batches = len(inference_ds) // batch_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/Users/user010/Desktop/Programming/ML/En2RuTranslator/venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:33<17:07, 33.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2/32 [01:01<15:06, 30.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [01:35<15:33, 32.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 4/32 [02:11<15:43, 33.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5/32 [02:45<15:10, 33.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6/32 [03:19<14:40, 33.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 7/32 [03:55<14:20, 34.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 8/32 [04:21<12:40, 31.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 9/32 [04:45<11:16, 29.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 10/32 [05:16<10:57, 29.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 11/32 [05:38<09:39, 27.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 12/32 [06:05<09:08, 27.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 13/32 [06:37<09:05, 28.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 14/32 [07:33<11:07, 37.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 15/32 [07:59<09:30, 33.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 16/32 [08:40<09:32, 35.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 17/32 [09:18<09:08, 36.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 18/32 [09:54<08:28, 36.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 19/32 [10:20<07:09, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 20/32 [10:41<05:55, 29.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 21/32 [11:07<05:12, 28.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 22/32 [11:41<05:02, 30.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 23/32 [12:26<05:12, 34.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 24/32 [13:55<06:47, 50.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 25/32 [14:24<05:10, 44.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 26/32 [14:59<04:09, 41.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 27/32 [15:38<03:23, 40.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 28/32 [16:10<02:32, 38.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 29/32 [16:48<01:54, 38.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 30/32 [17:16<01:09, 34.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 31/32 [17:52<00:35, 35.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [18:12<00:00, 34.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# nnlb\n",
    "translations = []\n",
    "for i in tqdm(range(num_batches)):\n",
    "    batch = inference_ds.iloc[i*batch_size:(i+1)*batch_size][\"source\"].tolist()\n",
    "    batch_translations = get_translations(nnlb_model, nnlb_tokenizer, batch,\n",
    "                                          special_gen_params={\"forced_bos_token_id\": nnlb_tokenizer.lang_code_to_id[\"rus_Cyrl\"]})\n",
    "    translations.extend(batch_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_ds[cfg.nnlb_model.name] = translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:11<05:50, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2/32 [00:22<05:35, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [00:33<05:19, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 4/32 [00:46<05:28, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5/32 [00:57<05:09, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6/32 [01:07<04:46, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 7/32 [01:17<04:31, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 8/32 [01:26<04:02, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 9/32 [01:34<03:41,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 10/32 [01:44<03:33,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 11/32 [01:53<03:15,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 12/32 [02:01<03:03,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 13/32 [02:08<02:41,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 14/32 [02:22<03:02, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 15/32 [02:39<03:25, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 16/32 [03:00<03:54, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 17/32 [03:13<03:35, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 18/32 [03:21<02:55, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 19/32 [03:31<02:31, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 20/32 [03:39<02:08, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 21/32 [03:52<02:02, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 22/32 [04:01<01:46, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 23/32 [04:13<01:40, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 24/32 [04:51<02:31, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 25/32 [04:59<01:50, 15.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 26/32 [05:11<01:27, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 27/32 [05:22<01:07, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 28/32 [05:43<01:03, 15.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 29/32 [05:56<00:45, 15.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 30/32 [06:06<00:27, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 31/32 [06:21<00:13, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n",
      "Tokenizing...\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [06:23<00:00, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# opus\n",
    "translations = []\n",
    "for i in tqdm(range(num_batches)):\n",
    "    batch = inference_ds.iloc[i*batch_size:(i+1)*batch_size][\"source\"].tolist()\n",
    "    batch_translations = get_translations(opus_model, opus_tokenizer, batch)\n",
    "    translations.extend(batch_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_ds[cfg.opus_model.name] = translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>transformer-en-ru</th>\n",
       "      <th>nnlb-1.3B-distilled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The intention would also be to infiltrate terr...</td>\n",
       "      <td>Террористов также обучают методам проникновени...</td>\n",
       "      <td>Кроме того, намерение состоит в том, чтобы про...</td>\n",
       "      <td>Имеется в виду также проникновение террористов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Officials say that as the latest information a...</td>\n",
       "      <td>По последним данным представителей власти , в ...</td>\n",
       "      <td>Официальные лица говорят, что в качестве самой...</td>\n",
       "      <td>Официальные лица говорят, что по последней инф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While the Balakot camp was reactivated by the ...</td>\n",
       "      <td>Джаиш-е-Мухаммад возобновили работу террористи...</td>\n",
       "      <td>В то время как лагерь в Балакоте был восстанов...</td>\n",
       "      <td>В то время как лагерь Балакота был активирован...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The incident in which Pakistan used drones to ...</td>\n",
       "      <td>В качестве яркого примера новой стратегии паки...</td>\n",
       "      <td>Инцидент, в ходе которого Пакистан использовал...</td>\n",
       "      <td>Инцидент, когда Пакистан использовал беспилотн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Officials tell OneIndia that terror groups wou...</td>\n",
       "      <td>Представители власти рассказали порталу OneInd...</td>\n",
       "      <td>Официальные лица сообщают одной Индии, что тер...</td>\n",
       "      <td>Официальные лица говорят OneIndia, что террори...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  The intention would also be to infiltrate terr...   \n",
       "1  Officials say that as the latest information a...   \n",
       "2  While the Balakot camp was reactivated by the ...   \n",
       "3  The incident in which Pakistan used drones to ...   \n",
       "4  Officials tell OneIndia that terror groups wou...   \n",
       "\n",
       "                                              target  \\\n",
       "0  Террористов также обучают методам проникновени...   \n",
       "1  По последним данным представителей власти , в ...   \n",
       "2  Джаиш-е-Мухаммад возобновили работу террористи...   \n",
       "3  В качестве яркого примера новой стратегии паки...   \n",
       "4  Представители власти рассказали порталу OneInd...   \n",
       "\n",
       "                                   transformer-en-ru  \\\n",
       "0  Кроме того, намерение состоит в том, чтобы про...   \n",
       "1  Официальные лица говорят, что в качестве самой...   \n",
       "2  В то время как лагерь в Балакоте был восстанов...   \n",
       "3  Инцидент, в ходе которого Пакистан использовал...   \n",
       "4  Официальные лица сообщают одной Индии, что тер...   \n",
       "\n",
       "                                 nnlb-1.3B-distilled  \n",
       "0  Имеется в виду также проникновение террористов...  \n",
       "1  Официальные лица говорят, что по последней инф...  \n",
       "2  В то время как лагерь Балакота был активирован...  \n",
       "3  Инцидент, когда Пакистан использовал беспилотн...  \n",
       "4  Официальные лица говорят OneIndia, что террори...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_ds.to_csv(cfg.result_dataset.path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
