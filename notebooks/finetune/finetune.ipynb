{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0.dev0)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0a0+32f93b1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.12)\n",
      "Collecting hydra-core\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.24.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.18)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.32.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core) (4.9.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Installing collected packages: hydra-core\n",
      "Successfully installed hydra-core-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets transformers sacrebleu torch sentencepiece \"transformers[sentencepiece]\" huggingface_hub wandb hydra-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/rodion/other/trans\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "print(root_dir)\n",
    "assert os.path.exists(root_dir), f'Could not find root directory at {root_dir}'\n",
    "sys.path.insert(0, root_dir)\n",
    "\n",
    "from custom_utils.config_handler import read_config, pprint_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"root\": \"/home/jovyan/rodion/other/trans\",\n",
      "  \"dataset\": {\n",
      "    \"path\": \"waleko/unarXive-en2ru\"\n",
      "  },\n",
      "  \"params\": {\n",
      "    \"batch_size\": 16,\n",
      "    \"max_length\": 512,\n",
      "    \"train_args\": {\n",
      "      \"evaluation_strategy\": \"epoch\",\n",
      "      \"learning_rate\": 2e-05,\n",
      "      \"per_device_train_batch_size\": 16,\n",
      "      \"per_device_eval_batch_size\": 16,\n",
      "      \"weight_decay\": 0.01,\n",
      "      \"save_total_limit\": 3,\n",
      "      \"num_train_epochs\": 4,\n",
      "      \"predict_with_generate\": true\n",
      "    },\n",
      "    \"wandb_args\": {\n",
      "      \"report_to\": \"wandb\",\n",
      "      \"run_name\": \"finetune\"\n",
      "    }\n",
      "  },\n",
      "  \"pretrained\": {\n",
      "    \"name\": \"opus-en-ru\",\n",
      "    \"model_and_tokenizer_name\": \"Helsinki-NLP/opus-mt-en-ru\"\n",
      "  },\n",
      "  \"finetuned\": {\n",
      "    \"name\": \"opus-distilled-en-ru\",\n",
      "    \"model_and_tokenizer_name\": \"under-tree/transformer-en-ru\",\n",
      "    \"output_dir\": \"/home/jovyan/rodion/other/trans/models/opus-distilled-en-ru/finetuned\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "overrides = [\"setup=finetune\"]\n",
    "cfg = read_config(overrides=overrides)\n",
    "pprint_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688ebf26fce74939bd55e43ab219eafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to Hugging Face as: under-tree\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Create an instance of HfApi\n",
    "api = HfApi()\n",
    "\n",
    "# Check if logged in and get username\n",
    "try:\n",
    "    user_info = api.whoami()\n",
    "    username = user_info['name']\n",
    "    print(f\"Logged in to Hugging Face as: {username}\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Not logged in to Hugging Face.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/user/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrodionkhvorostov\u001b[0m (\u001b[33mwide-learning\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=true\n",
      "env: WANDB_WATCH=true\n",
      "env: WANDB_NOTEBOOK=finetune\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_LOG_MODEL=true\n",
    "%env WANDB_WATCH=true\n",
    "%env WANDB_NOTEBOOK=finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35.0.dev0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f72037662c419e81ebbad36283d977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/751 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e7453e7dc24d10ad8e9e86bdbb2e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832b720a169947d58682eb15e1f85609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430518a323e24a7b9888f4ce87c794db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/652k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92824d7b1254442b988580256909d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/550k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feef99de3c694450a9b84345ba0207d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49661b4332d471b99d8972fb1983e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5d28804d114bd29aceba168f8b0231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856d7b77bca7491b87d4138e49794427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n",
      "/tmp/ipykernel_341/1892407716.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc9fc3d9d1e43f7bb60e751ab8a2dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "raw_datasets = load_dataset(cfg.dataset.path)\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 9082\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 702\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 568\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': ['\\nA parametric approach requires assuming the form of the distribution with unknown parameters. The method of moments or the maximum likelihood methods are then applied to obtain the estimations of the unknown parameters.\\n\\nA non-parametric methods such as the kernel methods ([1]}, [2]}, [3]}, [4]}) and the empirical distribution (i.e., \\\\(F_n\\\\) ) avoid any assumption about the form of the distribution.\\n\\nA combination of both approaches can lead to a semi-parametric methods.\\n\\n',\n",
       "  'The Bardeen solution has motivated deeper works about singularity avoidance may be realized generally. Several other researchers paid attention to theories of gravity coupled to nonlinear electrodynamics, and proposed other solutions in different contexts. Some solutions that are relevant to this work are analyzed in Refs. [1]}, [2]}, [3]}, [4]}, [5]} and Refs. [6]}, [7]}.\\n',\n",
       "  'In typical implementations, one possibility is to exploit the structure of the underlying PDE to set many of the coefficients \\\\(c_k(x,y)\\\\)  to zero a priori and obtain closed form expressions for the (small) number of non-zero coefficients\\xa0[1]}. Another option is to use simple analytical and computational optimization tools to numerically determine the values of the coefficients and establish bounds needed to ensure consistency\\xa0[2]}, [3]}.\\n'],\n",
       " 'target': ['Параметрический подход предполагает, что форма распределения с неизвестными параметрами известна. Затем применяются методы моментов или метод максимального правдоподобия для получения оценок неизвестных параметров.\\n\\n\\n\\nНепараметрические методы, такие как метод ядерной регрессии ([1], [2], [3], [4]) и эмпирическое распределение (то есть \\\\(F_n\\\\)), не предполагают никакой формы распределения.\\n\\n\\n\\nКомбинация обоих подходов может привести к полупараметрическим методам.',\n",
       "  'Решение Бардина вызвало интерес к более глубоким работам о возможности избежания сингулярности в общем случае. Некоторые другие исследователи обратили внимание на теории гравитации, связанные с нелинейной электродинамикой, и предложили другие решения в различных контекстах. Некоторые решения, связанные с этой работой, были проанализированы в работах [1]}, [2]}, [3]}, [4]}, [5]} и работах [6]}, [7]}.',\n",
       "  'В типичных реализациях можно воспользоваться структурой базового уравнения в частных производных (PDE), чтобы заранее установить многие коэффициенты \\\\(c_k(x,y)\\\\) равными нулю и получить явные выражения для (небольшого) количества ненулевых коэффициентов [1]. Другой вариант - использовать простые аналитические и вычислительные инструменты оптимизации для численного определения значений коэффициентов и установления необходимых ограничений для обеспечения согласованности [2], [3].']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 3\n",
    "rnd_idx = np.random.randint(0, len(raw_datasets[\"train\"]), n)\n",
    "raw_datasets[\"train\"][rnd_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0,\n",
       " 'counts': [4, 2, 0, 0],\n",
       " 'totals': [4, 2, 0, 0],\n",
       " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = [\"hello there\", \"general kenobi\"]\n",
    "fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012c60a8578a42f7b46296036bda70b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b210967c470408698e4c3d1d7ba4224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84746ce14b54414489e95ee68ad789de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/803k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20619d56753e4d5dba92331af9b9df89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/target.spm:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f62643896a4801a5247cbf2d102f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/2.60M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e256e380f2440e9281c77b9412d150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/307M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb32ed1e1d324d0491c94d7daec9f925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.pretrained.model_and_tokenizer_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(cfg.pretrained.model_and_tokenizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for such tokenization difference (as I think) is that actually for ru, and for en are used different tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens usual: {'input_ids': [[21, 2408, 779, 53, 222, 30, 275, 2, 21, 46, 53, 779, 56, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "Tokens target: {'input_ids': [[543, 1877, 2, 1920, 56, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3854: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "example_sample = [\"Привет, мир!\"]\n",
    "tokens_usual = tokenizer(example_sample)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    tokens_target = tokenizer(example_sample)\n",
    "\n",
    "print(\"Tokens usual:\", tokens_usual)\n",
    "print(\"Tokens target:\", tokens_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = cfg.params.max_length\n",
    "\n",
    "# remove\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex for ex in examples[\"source\"]]\n",
    "    targets = [ex for ex in examples[\"target\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=max_length, truncation=True)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[156, 1747, 4, 2877, 5, 338, 791, 289, 35659, 592, 2168, 11, 1491, 20, 26007, 4, 18426, 21, 58925, 1728, 2, 4657, 8220, 25, 542, 42118, 35409, 237, 12281, 2, 1113, 37966, 2293, 43511, 237, 12281, 2, 29, 11, 17992, 2637, 6786, 49308, 237, 12281, 2, 1113, 37966, 2293, 11, 2088, 9318, 202, 1565, 237, 12281, 2, 8, 1220, 11, 1291, 27328, 50881, 237, 12281, 3, 30276, 188, 4, 57893, 127, 36, 1179, 10, 4, 23571, 3, 13988, 2, 105, 12905, 4, 29850, 5812, 5, 338, 34254, 23, 2, 3758, 39, 4, 1133, 5, 310, 31483, 8, 4, 1717, 1880, 5, 5630, 1133, 2, 201, 77, 13, 32154, 1969, 1747, 5, 338, 289, 35659, 592, 2168, 11, 1491, 3, 0], [2470, 35588, 118, 29050, 23, 20, 21, 16779, 1145, 91, 57655, 39634, 1114, 11, 166, 12281, 16779, 24, 10, 14, 7825, 2088, 21, 117, 105, 5719, 4, 542, 9665, 592, 2526, 14236, 23, 20, 4, 1221, 17240, 1969, 8416, 16681, 3876, 104, 5967, 23, 2, 81, 55, 13, 2506, 427, 58437, 5, 27170, 14, 47763, 24, 10, 35409, 237, 12281, 64, 27170, 17408, 10073, 10, 43511, 237, 12281, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[231, 48206, 4424, 4419, 13729, 57, 289, 196, 2637, 592, 2168, 11, 1491, 40, 524, 12759, 816, 1113, 18842, 2, 6, 5002, 16, 3072, 4932, 11130, 4984, 41, 4995, 17, 542, 2552, 1949, 202, 858, 237, 2, 1113, 196, 2637, 6786, 202, 796, 237, 2, 29, 11, 2168, 196, 2637, 6786, 202, 1166, 237, 2, 1113, 196, 2637, 6786, 11, 2088, 9318, 202, 1565, 237, 7, 1220, 11, 14113, 1847, 1949, 202, 2672, 3583, 19572, 1001, 35, 10856, 44, 643, 533, 2523, 6, 8840, 44, 22676, 3, 6772, 164, 35, 3439, 12475, 7511, 391, 20471, 3281, 16, 53, 504, 1057, 11276, 2, 72, 3366, 29307, 1715, 368, 18299, 238, 7, 2724, 9412, 8517, 1283, 6027, 1640, 2, 351, 5915, 4868, 4419, 289, 196, 2637, 592, 2168, 11, 1491, 3, 0], [44773, 10495, 35516, 40, 21, 16779, 1145, 91, 57655, 39634, 1114, 11, 166, 12281, 16779, 24, 6, 14, 678, 23124, 117, 164, 18424, 33094, 3392, 985, 8226, 53, 40, 13944, 2926, 229, 24339, 11686, 991, 238, 2292, 300, 2, 119, 760, 28777, 72, 16179, 57, 46, 29164, 10035, 12554, 6, 202, 858, 237, 74, 29164, 17408, 10073, 6, 202, 796, 3583, 0]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(raw_datasets['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bbabe3e324475a8525423defb4cd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9082 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd966b6dd97a4a4481ed17e5c64d8322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a9b1cc6595486b9ad63169ebc55c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/568 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True, remove_columns=[\"source\", \"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(cfg.pretrained.model_and_tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"evaluation_strategy\": \"epoch\",\n",
      "  \"learning_rate\": 2e-05,\n",
      "  \"per_device_train_batch_size\": 16,\n",
      "  \"per_device_eval_batch_size\": 16,\n",
      "  \"weight_decay\": 0.01,\n",
      "  \"save_total_limit\": 3,\n",
      "  \"num_train_epochs\": 4,\n",
      "  \"predict_with_generate\": true\n",
      "}\n",
      "{\n",
      "  \"report_to\": \"wandb\",\n",
      "  \"run_name\": \"finetune\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pprint_config(cfg.params.train_args)\n",
    "pprint_config(cfg.params.wandb_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = cfg.pretrained.name\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    cfg.finetuned.output_dir,\n",
    "    **cfg.params.train_args,\n",
    "    **cfg.params.wandb_args,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=cfg.finetuned.model_and_tokenizer_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # The labels value for the text that is not being predicted gets set to -100. \n",
    "    # Replace these values with pad\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/rodion/other/trans/notebooks/finetune/wandb/run-20231117_130518-fgt5hc0j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wide-learning/huggingface/runs/fgt5hc0j' target=\"_blank\">finetune</a></strong> to <a href='https://wandb.ai/wide-learning/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wide-learning/huggingface' target=\"_blank\">https://wandb.ai/wide-learning/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wide-learning/huggingface/runs/fgt5hc0j' target=\"_blank\">https://wandb.ai/wide-learning/huggingface/runs/fgt5hc0j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2272' max='2272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2272/2272 20:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.941200</td>\n",
       "      <td>0.653884</td>\n",
       "      <td>67.599700</td>\n",
       "      <td>127.287700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.697700</td>\n",
       "      <td>0.608778</td>\n",
       "      <td>69.201200</td>\n",
       "      <td>127.783500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.631200</td>\n",
       "      <td>0.589383</td>\n",
       "      <td>69.907900</td>\n",
       "      <td>127.373200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.584227</td>\n",
       "      <td>70.363300</td>\n",
       "      <td>126.859000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2272, training_loss=0.6974154055958063, metrics={'train_runtime': 1218.4183, 'train_samples_per_second': 29.816, 'train_steps_per_second': 1.865, 'total_flos': 2196400063905792.0, 'train_loss': 0.6974154055958063, 'epoch': 4.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 06:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.7936033980595856\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity:\", np.exp(trainer.evaluate()[\"eval_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"eval_loss\": 0.6561718583106995,\n",
      "    \"eval_bleu\": 67.197,\n",
      "    \"eval_gen_len\": 126.7394,\n",
      "    \"eval_runtime\": 194.0045,\n",
      "    \"eval_samples_per_second\": 2.928,\n",
      "    \"eval_steps_per_second\": 0.186,\n",
      "    \"epoch\": 4.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "test_score = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "\n",
    "print(json.dumps(test_score, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▂▅▇██▁</td></tr><tr><td>eval/gen_len</td><td>▅█▅▂▂▁</td></tr><tr><td>eval/loss</td><td>█▃▂▁▁█</td></tr><tr><td>eval/runtime</td><td>██▇▇▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▁▆███</td></tr><tr><td>eval/steps_per_second</td><td>▁▁▅▆▆█</td></tr><tr><td>train/epoch</td><td>▁▁▃▄▅▆▇████</td></tr><tr><td>train/global_step</td><td>▁▁▃▄▅▆▇████</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>67.197</td></tr><tr><td>eval/gen_len</td><td>126.7394</td></tr><tr><td>eval/loss</td><td>0.65617</td></tr><tr><td>eval/runtime</td><td>194.0045</td></tr><tr><td>eval/samples_per_second</td><td>2.928</td></tr><tr><td>eval/steps_per_second</td><td>0.186</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>2272</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5876</td></tr><tr><td>train/total_flos</td><td>2196400063905792.0</td></tr><tr><td>train/train_loss</td><td>0.69742</td></tr><tr><td>train/train_runtime</td><td>1218.4183</td></tr><tr><td>train/train_samples_per_second</td><td>29.816</td></tr><tr><td>train/train_steps_per_second</td><td>1.865</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">finetune</strong> at: <a href='https://wandb.ai/wide-learning/huggingface/runs/fgt5hc0j' target=\"_blank\">https://wandb.ai/wide-learning/huggingface/runs/fgt5hc0j</a><br/> View job at <a href='https://wandb.ai/wide-learning/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExNjYyNzQ4OA==/version_details/v0' target=\"_blank\">https://wandb.ai/wide-learning/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExNjYyNzQ4OA==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231117_130518-fgt5hc0j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk(model_name):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e967b87fa3423a80769bccdb3972e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/816 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf51f961e98466bb49ea432e87c1f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/803k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca680be4b78b4822a7a3d12be593a98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading target.spm:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c097b50fdc22478ab8e8fcd0bfa056db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb76c06dcf14fe7bcbf6e380818db30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407558669c9d48f98d9acd0c45839c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f33e19b144e4a8d8f219c63a31cb26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/305M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3c748169f9419fbd877035ca2378cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "path = cfg.finetuned.model_and_tokenizer_name  # os.path.join(cfg.finetuned.output_dir, \"checkpoint-2000\")\n",
    "tokenizer = MarianTokenizer.from_pretrained(path)\n",
    "model = MarianMTModel.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_from_paper = \"Transformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length. Approximate attention methods have attempted to address this problem by trading off model quality to reduce the compute complexity, but often do not achieve wall-clock speedup. \"\n",
    "src_text = [sentence_from_paper]\n",
    "tokenized_text = tokenizer(src_text, return_tensors=\"pt\", padding=True)\n",
    "translated = model.generate(**tokenized_text)\n",
    "decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source\n",
      "('Transformers are slow and memory-hungry on long sequences, since the time '\n",
      " 'and memory complexity of self-attention are quadratic in sequence length. '\n",
      " 'Approximate attention methods have attempted to address this problem by '\n",
      " 'trading off model quality to reduce the compute complexity, but often do not '\n",
      " 'achieve wall-clock speedup. ')\n",
      "Target\n",
      "('Трансформеры медленны и страдают памятью на длинных последовательностях, так '\n",
      " 'как время и сложность памяти самовнимания квадратичны по длине '\n",
      " 'последовательности. Приближающиеся методы внимания пытались решить эту '\n",
      " 'проблему, отменяя качество модели, чтобы снизить сложность вычислений, но '\n",
      " 'часто не достигают ускорения на стене.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for src, tran in zip(src_text, decoded):\n",
    "    print(\"Source\")\n",
    "    pprint(src)\n",
    "    print(\"Target\")\n",
    "    pprint(tran)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
