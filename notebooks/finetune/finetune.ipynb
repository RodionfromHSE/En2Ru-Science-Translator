{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets transformers sacrebleu torch sentencepiece \"transformers[sentencepiece]\" huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user010/Desktop/Programming/ML/En2RuTranslator\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "print(root_dir)\n",
    "assert os.path.exists(root_dir), f'Could not find root directory at {root_dir}'\n",
    "sys.path.insert(0, root_dir)\n",
    "\n",
    "from custom_utils.config_handler import read_config, pprint_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"root\": \"/Users/user010/Desktop/Programming/ML/En2RuTranslator\",\n",
      "  \"dataset\": {\n",
      "    \"path\": \"waleko/unarXive-en2ru\"\n",
      "  },\n",
      "  \"params\": {\n",
      "    \"batch_size\": 16,\n",
      "    \"train_args\": {\n",
      "      \"evaluation_strategy\": \"epoch\",\n",
      "      \"learning_rate\": 2e-05,\n",
      "      \"per_device_train_batch_size\": 16,\n",
      "      \"per_device_eval_batch_size\": 16,\n",
      "      \"weight_decay\": 0.01,\n",
      "      \"save_total_limit\": 3,\n",
      "      \"num_train_epochs\": 4,\n",
      "      \"predict_with_generate\": true\n",
      "    }\n",
      "  },\n",
      "  \"pretrained\": {\n",
      "    \"name\": \"opus-en-ru\",\n",
      "    \"model_and_tokenizer_name\": \"Helsinki-NLP/opus-mt-en-ru\"\n",
      "  },\n",
      "  \"finetuned\": {\n",
      "    \"name\": \"opus-distilled-en-ru\",\n",
      "    \"model_and_tokenizer_name\": \"under-tree/transformer-en-ru\",\n",
      "    \"output_dir\": \"/Users/user010/Desktop/Programming/ML/En2RuTranslator/models/opus-distilled-en-ru/finetuned\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "overrides = [\"setup=finetune\"]\n",
    "cfg = read_config(overrides=overrides)\n",
    "pprint_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03f25be01ee4f25a50a363af150fe40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to Hugging Face as: under-tree\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Create an instance of HfApi\n",
    "api = HfApi()\n",
    "\n",
    "# Check if logged in and get username\n",
    "try:\n",
    "    user_info = api.whoami()\n",
    "    username = user_info['name']\n",
    "    print(f\"Logged in to Hugging Face as: {username}\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Not logged in to Hugging Face.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrodionkhvorostov\u001b[0m (\u001b[33mwide-learning\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=true\n",
      "env: WANDB_WATCH=true\n",
      "env: WANDB_NOTEBOOK=finetune\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_LOG_MODEL=true\n",
    "%env WANDB_WATCH=true\n",
    "%env WANDB_NOTEBOOK=finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.34.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g1/r3wb2hk9311bvwjfb1lz48700000gp/T/ipykernel_73505/1892407716.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "raw_datasets = load_dataset(cfg.dataset.path)\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 9082\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 702\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 568\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': ['eq:sgdup can be interpreted as stochastic differential equation ([1]}):\\n\\\\(\\\\begin{aligned}\\\\frac{d\\\\theta }{dt} & = \\\\mu , & \\\\frac{d\\\\mu }{dt} & = \\\\beta _t\\\\mu -\\\\frac{dL}{d\\\\theta } + \\\\eta _t\\\\end{aligned}\\\\) \\n',\n",
       "  \"blackIn view of Conrad's theorem\\xa0[1]}, we note that Conjecture\\xa0REF  implies the convergence in \\\\(\\\\Re (s) > 1/2\\\\) . blackHence Conjecture\\xa0REF  is stronger than RH.\\n\",\n",
       "  'Recalling (REF ) and that\\n\\\\(\\\\displaystyle \\\\bar{g}(\\\\cdot ,\\\\cdot )\\\\)  is a monotone numerical flux [1]}, [2]}, we have\\n\\\\(\\\\displaystyle \\\\mathcal {C}_{j+1/2}^n, \\\\mathcal {D}_{j-1/2}^n \\\\ge 0\\\\) .\\nMoreover, due to the CFL condition (REF ),\\nalong with the fact that \\\\(\\\\displaystyle L_g\\\\)  serves as a Lipschitz constant for\\n\\\\(\\\\displaystyle \\\\bar{g}(\\\\cdot ,\\\\cdot )\\\\) ,\\nwe also have\\n\\\\(\\\\mathcal {C}_{j+1/2}^n, \\\\mathcal {D}_{j-1/2}^n \\\\le \\\\lambda L_g L_{\\\\beta } \\\\le 1/2.\\\\) \\n'],\n",
       " 'target': ['eq:sgdup –º–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ ([1]):\\n\\n\\\\(\\\\begin{aligned}\\\\frac{d\\\\theta }{dt} & = \\\\mu , & \\\\frac{d\\\\mu }{dt} & = \\\\beta _t\\\\mu -\\\\frac{dL}{d\\\\theta } + \\\\eta _t\\\\end{aligned}\\\\)',\n",
       "  '–° —É—á–µ—Ç–æ–º —Ç–µ–æ—Ä–µ–º—ã –ö–æ–Ω—Ä–∞–¥–∞ [1] –º—ã –æ—Ç–º–µ—á–∞–µ–º, —á—Ç–æ –ü—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ REF –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø—Ä–∏ \\\\(\\\\Re (s) > 1/2\\\\) . –°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –ü—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ REF —è–≤–ª—è–µ—Ç—Å—è –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–º, —á–µ–º RH.',\n",
       "  '–ü–æ–º–Ω—è (REF) –∏ —á—Ç–æ \\\\(\\\\displaystyle \\\\bar{g}(\\\\cdot ,\\\\cdot )\\\\) —è–≤–ª—è–µ—Ç—Å—è –º–æ–Ω–æ—Ç–æ–Ω–Ω—ã–º —á–∏—Å–ª–æ–≤—ã–º –ø–æ—Ç–æ–∫–æ–º [1]}, [2]}, —É –Ω–∞—Å –µ—Å—Ç—å \\\\(\\\\displaystyle \\\\mathcal {C}_{j+1/2}^n, \\\\mathcal {D}_{j-1/2}^n \\\\ge 0\\\\).\\n\\n–ë–æ–ª–µ–µ —Ç–æ–≥–æ, –∏–∑ —É—Å–ª–æ–≤–∏—è CFL (REF), –≤–º–µ—Å—Ç–µ —Å —Ç–µ–º, —á—Ç–æ \\\\(\\\\displaystyle L_g\\\\) —Å–ª—É–∂–∏—Ç –∫–æ–Ω—Å—Ç–∞–Ω—Ç–æ–π –õ–∏–ø—à–∏—Ü–∞ –¥–ª—è \\\\(\\\\displaystyle \\\\bar{g}(\\\\cdot ,\\\\cdot )\\\\), –º—ã —Ç–∞–∫–∂–µ –∏–º–µ–µ–º \\\\(\\\\mathcal {C}_{j+1/2}^n, \\\\mathcal {D}_{j-1/2}^n \\\\le \\\\lambda L_g L_{\\\\beta } \\\\le 1/2.\\\\)']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 3\n",
    "rnd_idx = np.random.randint(0, len(raw_datasets[\"train\"]), n)\n",
    "raw_datasets[\"train\"][rnd_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0,\n",
       " 'counts': [4, 2, 0, 0],\n",
       " 'totals': [4, 2, 0, 0],\n",
       " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = [\"hello there\", \"general kenobi\"]\n",
    "fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.pretrained.model_and_tokenizer_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(cfg.pretrained.model_and_tokenizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for such tokenization difference (as I think) is that actually for ru, and for en are used different tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens usual: {'input_ids': [[21, 2408, 779, 53, 222, 30, 275, 2, 21, 46, 53, 779, 56, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "Tokens target: {'input_ids': [[543, 1877, 2, 1920, 56, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3854: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "example_sample = [\"–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!\"]\n",
    "tokens_usual = tokenizer(example_sample)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    tokens_target = tokenizer(example_sample)\n",
    "\n",
    "print(\"Tokens usual:\", tokens_usual)\n",
    "print(\"Tokens target:\", tokens_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = cfg.params.max_length\n",
    "\n",
    "# remove\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex for ex in examples[\"source\"]]\n",
    "    targets = [ex for ex in examples[\"target\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=max_length, truncation=True)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[156, 1747, 4, 2877, 5, 338, 791, 289, 35659, 592, 2168, 11, 1491, 20, 26007, 4, 18426, 21, 58925, 1728, 2, 4657, 8220, 25, 542, 42118, 35409, 237, 12281, 2, 1113, 37966, 2293, 43511, 237, 12281, 2, 29, 11, 17992, 2637, 6786, 49308, 237, 12281, 2, 1113, 37966, 2293, 11, 2088, 9318, 202, 1565, 237, 12281, 2, 8, 1220, 11, 1291, 27328, 50881, 237, 12281, 3, 30276, 188, 4, 57893, 127, 36, 1179, 10, 4, 23571, 3, 13988, 2, 105, 12905, 4, 29850, 5812, 5, 338, 34254, 23, 2, 3758, 39, 4, 1133, 5, 310, 31483, 8, 4, 1717, 1880, 5, 5630, 1133, 2, 201, 77, 13, 32154, 1969, 1747, 5, 338, 289, 35659, 592, 2168, 11, 1491, 3, 0], [2470, 35588, 118, 29050, 23, 20, 21, 16779, 1145, 91, 57655, 39634, 1114, 11, 166, 12281, 16779, 24, 10, 14, 7825, 2088, 21, 117, 105, 5719, 4, 542, 9665, 592, 2526, 14236, 23, 20, 4, 1221, 17240, 1969, 8416, 16681, 3876, 104, 5967, 23, 2, 81, 55, 13, 2506, 427, 58437, 5, 27170, 14, 47763, 24, 10, 35409, 237, 12281, 64, 27170, 17408, 10073, 10, 43511, 237, 12281, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[231, 48206, 4424, 4419, 13729, 57, 289, 196, 2637, 592, 2168, 11, 1491, 40, 524, 12759, 816, 1113, 18842, 2, 6, 5002, 16, 3072, 4932, 11130, 4984, 41, 4995, 17, 542, 2552, 1949, 202, 858, 237, 2, 1113, 196, 2637, 6786, 202, 796, 237, 2, 29, 11, 2168, 196, 2637, 6786, 202, 1166, 237, 2, 1113, 196, 2637, 6786, 11, 2088, 9318, 202, 1565, 237, 7, 1220, 11, 14113, 1847, 1949, 202, 2672, 3583, 19572, 1001, 35, 10856, 44, 643, 533, 2523, 6, 8840, 44, 22676, 3, 6772, 164, 35, 3439, 12475, 7511, 391, 20471, 3281, 16, 53, 504, 1057, 11276, 2, 72, 3366, 29307, 1715, 368, 18299, 238, 7, 2724, 9412, 8517, 1283, 6027, 1640, 2, 351, 5915, 4868, 4419, 289, 196, 2637, 592, 2168, 11, 1491, 3, 0], [44773, 10495, 35516, 40, 21, 16779, 1145, 91, 57655, 39634, 1114, 11, 166, 12281, 16779, 24, 6, 14, 678, 23124, 117, 164, 18424, 33094, 3392, 985, 8226, 53, 40, 13944, 2926, 229, 24339, 11686, 991, 238, 2292, 300, 2, 119, 760, 28777, 72, 16179, 57, 46, 29164, 10035, 12554, 6, 202, 858, 237, 74, 29164, 17408, 10073, 6, 202, 796, 3583, 0]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(raw_datasets['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cfca8f96d44c75ac4edb430a975fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9082 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981c3b50e963416db3e708bf8e3c85c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59d6cbb07c640aa8a71e4468c3789d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/568 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True, remove_columns=[\"source\", \"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(cfg.pretrained.model_and_tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"evaluation_strategy\": \"epoch\",\n",
      "  \"learning_rate\": 2e-05,\n",
      "  \"per_device_train_batch_size\": 16,\n",
      "  \"per_device_eval_batch_size\": 16,\n",
      "  \"weight_decay\": 0.01,\n",
      "  \"save_total_limit\": 3,\n",
      "  \"num_train_epochs\": 4,\n",
      "  \"predict_with_generate\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pprint_config(cfg.params.train_args)\n",
    "pprint_config(cfg.params.wandb_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = cfg.pretrained.name\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    cfg.finetuned.output_dir,\n",
    "    **cfg.params.train_args,\n",
    "    **cfg.params.wandb_args,\n",
    "    push_to_hub=True,\n",
    "    push_to_hub_model_id=cfg.fineturned.model_and_tokenizer_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # The labels value for the text that is not being predicted gets set to -100. \n",
    "    # Replace these values with pad\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2272' max='2272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2272/2272 13:43, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.793700</td>\n",
       "      <td>0.637279</td>\n",
       "      <td>68.099600</td>\n",
       "      <td>127.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.672800</td>\n",
       "      <td>0.602759</td>\n",
       "      <td>69.623200</td>\n",
       "      <td>127.266400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.613600</td>\n",
       "      <td>0.585267</td>\n",
       "      <td>70.206800</td>\n",
       "      <td>126.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.573300</td>\n",
       "      <td>0.580561</td>\n",
       "      <td>70.227400</td>\n",
       "      <td>127.215100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2272, training_loss=0.6508109871770295, metrics={'train_runtime': 824.2424, 'train_samples_per_second': 44.074, 'train_steps_per_second': 2.756, 'total_flos': 2196400063905792.0, 'train_loss': 0.6508109871770295, 'epoch': 4.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 08:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.7870409672014942\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity:\", np.exp(trainer.evaluate()[\"eval_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"eval_loss\": 0.6526695489883423,\n",
      "    \"eval_bleu\": 67.1147,\n",
      "    \"eval_gen_len\": 127.0651,\n",
      "    \"eval_runtime\": 90.1349,\n",
      "    \"eval_samples_per_second\": 6.302,\n",
      "    \"eval_steps_per_second\": 0.399,\n",
      "    \"epoch\": 4.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "test_score = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "\n",
    "print(json.dumps(test_score, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer-en-ru/runs/Nov12_20-10-54_rodion-test-0/events.out.tfevents.1699809060.rodion-test-0.144.0\n",
      "transformer-en-ru/runs/Nov12_20-11-35_rodion-test-0/events.out.tfevents.1699809122.rodion-test-0.144.1\n",
      "transformer-en-ru/runs/Nov12_20-11-35_rodion-test-0/events.out.tfevents.1699810101.rodion-test-0.144.2\n",
      "transformer-en-ru/checkpoint-1000/config.json\n",
      "transformer-en-ru/checkpoint-1000/generation_config.json\n",
      "transformer-en-ru/checkpoint-1000/model.safetensors\n",
      "transformer-en-ru/checkpoint-1000/tokenizer_config.json\n",
      "transformer-en-ru/checkpoint-1000/special_tokens_map.json\n",
      "transformer-en-ru/checkpoint-1000/vocab.json\n",
      "transformer-en-ru/checkpoint-1000/source.spm\n",
      "transformer-en-ru/checkpoint-1000/target.spm\n",
      "transformer-en-ru/checkpoint-1000/training_args.bin\n",
      "transformer-en-ru/checkpoint-1000/optimizer.pt\n",
      "transformer-en-ru/checkpoint-1000/scheduler.pt\n",
      "transformer-en-ru/checkpoint-1000/trainer_state.json\n",
      "transformer-en-ru/checkpoint-1000/rng_state.pth\n",
      "transformer-en-ru/checkpoint-1500/config.json\n",
      "transformer-en-ru/checkpoint-1500/generation_config.json\n",
      "transformer-en-ru/checkpoint-1500/model.safetensors\n",
      "transformer-en-ru/checkpoint-1500/tokenizer_config.json\n",
      "transformer-en-ru/checkpoint-1500/special_tokens_map.json\n",
      "transformer-en-ru/checkpoint-1500/vocab.json\n",
      "transformer-en-ru/checkpoint-1500/source.spm\n",
      "transformer-en-ru/checkpoint-1500/target.spm\n",
      "transformer-en-ru/checkpoint-1500/training_args.bin\n",
      "transformer-en-ru/checkpoint-1500/optimizer.pt\n",
      "transformer-en-ru/checkpoint-1500/scheduler.pt\n",
      "transformer-en-ru/checkpoint-1500/trainer_state.json\n",
      "transformer-en-ru/checkpoint-1500/rng_state.pth\n",
      "transformer-en-ru/checkpoint-2000/config.json\n",
      "transformer-en-ru/checkpoint-2000/generation_config.json\n",
      "transformer-en-ru/checkpoint-2000/model.safetensors\n",
      "transformer-en-ru/checkpoint-2000/tokenizer_config.json\n",
      "transformer-en-ru/checkpoint-2000/special_tokens_map.json\n",
      "transformer-en-ru/checkpoint-2000/vocab.json\n",
      "transformer-en-ru/checkpoint-2000/source.spm\n",
      "transformer-en-ru/checkpoint-2000/target.spm\n",
      "transformer-en-ru/checkpoint-2000/training_args.bin\n",
      "transformer-en-ru/checkpoint-2000/optimizer.pt\n",
      "transformer-en-ru/checkpoint-2000/scheduler.pt\n",
      "transformer-en-ru/checkpoint-2000/trainer_state.json\n",
      "transformer-en-ru/checkpoint-2000/rng_state.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk(model_name):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "path = cfg.finetuned.model_and_tokenizer_name  # os.path.join(cfg.finetuned.output_dir, \"checkpoint-2000\")\n",
    "tokenizer = MarianTokenizer.from_pretrained(path)\n",
    "model = MarianMTModel.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_from_paper = \"Transformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length. Approximate attention methods have attempted to address this problem by trading off model quality to reduce the compute complexity, but often do not achieve wall-clock speedup. \"\n",
    "src_text = [sentence_from_paper]\n",
    "tokenized_text = tokenizer(src_text, return_tensors=\"pt\", padding=True)\n",
    "translated = model.generate(**tokenized_text)\n",
    "decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source\n",
      "('Transformers are slow and memory-hungry on long sequences, since the time '\n",
      " 'and memory complexity of self-attention are quadratic in sequence length. '\n",
      " 'Approximate attention methods have attempted to address this problem by '\n",
      " 'trading off model quality to reduce the compute complexity, but often do not '\n",
      " 'achieve wall-clock speedup. ')\n",
      "Target\n",
      "('–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∏ —Å—Ç—Ä–∞–¥–∞—é—Ç –ø–∞–º—è—Ç—å—é –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è—Ö, '\n",
      " '—Ç–∞–∫ –∫–∞–∫ –≤—Ä–µ–º—è –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏ —Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏—è –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—ã –ø–æ –¥–ª–∏–Ω–µ '\n",
      " '–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ú–µ—Ç–æ–¥—ã –ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –ø—ã—Ç–∞—é—Ç—Å—è —Ä–µ—à–∏—Ç—å —ç—Ç—É '\n",
      " '–ø—Ä–æ–±–ª–µ–º—É, –æ—Ç–º–µ–Ω—è—è –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã —Å–Ω–∏–∑–∏—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, –Ω–æ '\n",
      " '—á–∞—Å—Ç–æ –Ω–µ –¥–æ—Å—Ç–∏–≥–∞—é—Ç —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ —Å—Ç–µ–Ω–µ.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for src, tran in zip(src_text, decoded):\n",
    "    print(\"Source\")\n",
    "    pprint(src)\n",
    "    print(\"Target\")\n",
    "    pprint(tran)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
